%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Welcome to writeLaTeX --- just edit your LaTeX on the left,
% and we'll compile it for you on the right. If you give
% someone the link to this page, they can edit at the same
% time. See the help menu above for more info. Enjoy!
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------
 
\documentclass[12pt]{article}
 
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{enumitem}

\setlist[enumerate,1]{label={(\alph*)}} %this changes enumerate to (a),(b),...

\usepackage{graphicx} %package to manage images

\newcommand{\A}{{\mathcal{A}}}
\newcommand{\C}{{\mathbb C}}
\newcommand{\CC}{{\mathcal{C}}}
\newcommand{\N}{{\mathbb N}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\Z}{{\mathbb Z}}

\newcommand{\Aut}{{\rm Aut}}
\newcommand{\End}{{\rm End}}
\newcommand{\Hom}{{\rm Hom}}
\newcommand{\id}{{\rm id}}
\newcommand{\Ima}{{\rm Im}}
\newcommand{\Ker}{{\rm Ker}}
\newcommand{\Mor}{{\rm Mor}}
\newcommand{\Rad}{{\rm Rad}}
\newcommand{\Prob}{{\rm P}}

\renewcommand\labelitemi{-} %this changes itemize bullet points to dashes (-)

\usepackage{listings}
\usepackage{xcolor}

%New colors defined below
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

%Code listing style named "mystyle"
\lstdefinestyle{mystyle}{
  backgroundcolor=\color{backcolour}, commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\ttfamily\footnotesize,
  breakatwhitespace=false,         
  breaklines=true,                 
  captionpos=b,                    
  keepspaces=true,                 
  numbers=left,                    
  numbersep=5pt,                  
  showspaces=false,                
  showstringspaces=false,
  showtabs=false,                  
  tabsize=2
}

%"mystyle" code listing set
\lstset{style=mystyle}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}
{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}
{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}
{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}
{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}
{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}
{\end{trivlist}}

\newenvironment{solution}{\begin{proof}[Solution]}{\end{proof}}
 
\begin{document}
 
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------
 
\title{Homework 1}%replace X with the appropriate number
\author{Mengxiang Jiang\\ %replace with your name
Stat 610 Distribution Theory} %if necessary, replace with your course title
 
\maketitle
 
\begin{problem}{1} %You can use theorem, exercise, problem, or question here.
  \textit{Statistical Inference} by Casella and Berger, 2nd Edition, Chapter 1, 
  Exercise 4, 5, and 6.
  \begin{itemize}
    \item[4] For events $A$ and $B$, find formulas for the probabilities of the 
    following events in terms of the quantities $P(A)$, $P(B)$, and $P(A \cap B)$.
      \begin{itemize}
        \item[(a)] either $A$ or $B$ or both
        \item[(b)] either $A$ or $B$ but not both
        \item[(c)] at least one of $A$ or $B$
        \item[(d)] at most one of $A$ or $B$
      \end{itemize}
      \begin{itemize}
        \item[(a)] $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
        \item[(b)] $P(A \cup B) - P(A \cap B) = P(A) + P(B) - 2P(A \cap B)$
        \item[(c)] $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
        \item[(d)] $1 - P(A \cap B)$
      \end{itemize}
    \item[5] Approximately one-third of all human twins are identical 
    (one-egg) and two-thirds are fraternal (two-egg) twins. Identical twins 
    are necessarily the same sex, with male and female being equally likely.
    Among fraternal twins, approximately one-fourth are both female, one-fourth
    are both male, and half are one male and one female. Finally, among all
    U.S. births, approximately 1 in 90 is a twin birth. Define the following
    events:
      \begin{itemize}
        \item $A$ = {the birth results in twin females}
        \item $B$ = {the twins are identical twins}
        \item $C$ = {a U.S. birth results in twins}
      \end{itemize}
      \begin{itemize}
        \item[(a)] State, in words, the event $A \cap B \cap C$.
        \item[(b)] Find $P(A \cap B \cap C)$.
      \end{itemize}
      \begin{itemize}
        \item[(a)] The event that a U.S. birth results in identical
        twin females.
        \item[(b)] From the given information, we have
        \begin{itemize}
          \item $P(C) = \frac{1}{90}$
          \item $P(B|C) = \frac{1}{3}$
          \item $P(A|B,C) = \frac{1}{2}$
        \end{itemize}
        So, $P(A \cap B \cap C) = P(C)P(B|C)P(A|B,C) = \frac{1}{90} \times
        \frac{1}{3} \times \frac{1}{2} = \frac{1}{540}$.
      \end{itemize} 
    \item[6] Two pennies, one with $P(\text{head}) = u$ and one with
    $P(\text{head}) = w$, are to be tossed together independently. Define
    \begin{itemize}
      \item $p_0 = P(\text{0 heads occur})$,
      \item $p_1 = P(\text{1 head occurs})$,
      \item $p_2 = P(\text{2 heads occur})$.
    \end{itemize}
    Can $u$ and $w$ be chosen so that $p_0 = p_1 = p_2$? Prove your answer.
    \\\\
    We have
    \begin{itemize}
      \item $p_0 = (1-u)(1-w)$,
      \item $p_1 = u(1-w) + w(1-u)$,
      \item $p_2 = uw$.
    \end{itemize}
    So, $p_0 = p_2$ implies $(1-u)(1-w) = uw$, which simplifies to
    $u + w = 1$. Also, $p_1 = p_2$ implies $u(1-w) + w(1-u) = uw$, which
    simplifies to $ u + w = 3uw$. Combining these two equations, we have
    $3uw = 1$, or $uw = \frac{1}{3}$. However, since $u + w = 1$, by AM-GM
    inequality, we have $\frac{u+w}{2} = \frac{1}{2} \ge \sqrt{uw}$, which
    when squared gives $\frac{1}{4} \ge uw$. This
    contradicts $uw = \frac{1}{3}$. Therefore, there are no such $u$ and $w$,
    assuming they are both in $[0,1]$.
  \end{itemize}
\end{problem}

\begin{problem}{2}
  Here is a sample space: $\mathcal{S} = \{a, b, c\}$.
  \begin{enumerate}
    \item Explicitly provide the $\sigma$-algebra of all subsets.
    \item Suppose one may only observe whether the outcome is $a$ or not.
    Explicitly provide the smallest relevant $\sigma$-algebra. Hint: what
    events may be obtained by complements, unions and intersections,
    starting only with ${a}$?
  \end{enumerate}
  \begin{enumerate}
    \item The $\sigma$-algebra of all subsets is
    \[
      \{\emptyset, \{a\}, \{b\}, \{c\}, \{a,b\}, \{a,c\}, \{b,c\}, \{a,b,c\}\}.
    \]
    \item 
    Starting with $\{a\}$, we may obtain $\{b,c\}$ by taking its complement.
    Then, we may obtain $\{a, b, c\}$ by taking the union of $\{a\}$ and
    $\{b,c\}$. Finally, we may obtain $\emptyset$ by taking the complement
    of $\{a, b, c\}$. Thus the smallest relevant $\sigma$-algebra is
    \[
    \{\emptyset, \{a\}, \{b,c\}, \{a,b,c\}\}.
    \]
  \end{enumerate}
\end{problem}

\begin{problem}{3}
  For each of the following, be sure to explicitly provide the sample space
  and the event indicated.
  \begin{enumerate}
    \item I hand out 4 pieces of candy at random, each to a child. There
    are three children and some will get more than others. Find the
    probability that each child gets at least one piece of candy. Find the
    probability that one child gets it all.
    \item The local Chevy dealer has 5 trucks to give away: two Silverados
    ($S_1$ and $S_2$), three Tahoes ($T_1$, $T_2$, and $T_3$). Suppose
    they randomly select a truck, give it to a lucky customer, and then
    randomly select another for a second lucky customer. Find the probability
    that $x$ Silverados are selected, where $x=0, 1, 2$.
  \end{enumerate}
  \begin{enumerate}
    \item The sample space is
    \[
      \mathcal{S} = \{(c_1, c_2, c_3, c_4) : c_i \in \{1, 2, 3\}\}.
    \]
    The event that each child gets at least one piece of candy is
    \[
      \begin{aligned}
      A = \{& (1,1,2,3), (1,1,3,2), (1,2,1,3), (1,2,2,3),\\ 
            & (1,2,3,1), (1,2,3,2), (1,2,3,3), (1,3,1,2),\\ 
            & (1,3,2,1), (1,3,2,2), (1,3,2,3), (1,3,3,2),\\
            & (2,1,1,3), (2,1,2,3), (2,1,3,1), (2,1,3,2),\\
            & (2,1,3,3), (2,2,1,3), (2,2,3,1), (2,3,1,1),\\
            & (2,3,1,2), (2,3,1,3), (2,3,2,1), (2,3,3,1),\\
            & (3,1,1,2), (3,1,2,1), (3,1,2,2), (3,1,2,3),\\
            & (3,1,3,2), (3,2,1,1), (3,2,1,2), (3,2,1,3),\\
            & (3,2,2,1), (3,2,3,1), (3,3,1,2), (3,3,2,1)\}.
      \end{aligned}
    \]
    The event that one child gets it all is
    \[
      B = \{(1,1,1,1), (2,2,2,2), (3,3,3,3)\}.
    \]
    Since each outcome in the sample space is equally likely, we have
    \[
      P(A) = \frac{36}{3^4} = \frac{4}{9}, \quad P(B) = \frac{3}{3^4} =
      \frac{1}{27}.
    \]    
    \item The sample space is
    \[
      \mathcal{S} = \{(x,y) : x, y \in \{S_1, S_2, T_1, T_2, T_3\}, x \neq y\}.
    \]
    The event that $x=0$ Silverados are selected is
    \[
      A = \{(T_1, T_2), (T_1, T_3), (T_2, T_1), (T_2, T_3), (T_3, T_1),
      (T_3, T_2)\}.
    \]
    The event that $x=1$ Silverados are selected is
    \[
      \begin{aligned}
      B = \{& (S_1, T_1), (S_1, T_2), (S_1, T_3),\\ 
            & (S_2, T_1), (S_2, T_2), (S_2, T_3),\\ 
            & (T_1, S_1), (T_1, S_2), (T_2, S_1),\\ 
            & (T_2, S_2), (T_3, S_1), (T_3, S_2)\}.
      \end{aligned}
    \]
    The event that $x=2$ Silverados are selected is
    \[
      C = \{(S_1, S_2), (S_2, S_1)\}.
    \]
    Since each outcome in the sample space is equally likely, we have
    \[
      P(A) = \frac{6}{20} = \frac{3}{10}, \quad P(B) = \frac{12}{20} =
      \frac{3}{5}, \quad P(C) = \frac{2}{20} = \frac{1}{10}.
    \]
  \end{enumerate}
\end{problem}

\begin{problem}{4} 
  \textit{Statistical Inference} by Casella and Berger, 2nd Edition, Chapter 1, 
  Exercise 10. Use the case $n = 2$ (Thm. 1.1.4.d in the book) and 
  \underline{mathematical induction} to solvee this.
  \begin{itemize}
    \item [10] Formulate and prove a version of DeMorgan's Laws that 
    applies to a finite collection of sets $A_1, A_2, \ldots, A_n$.
    \\\\
    For a finite collection of sets $A_1, A_2, \ldots, A_n$,
    we conjecture that the formulation is
    \[
      \left(\bigcap_{i=1}^n A_i\right)^c = \bigcup_{i=1}^nA_i^c.
    \]
    The other law is simply setting $B_i = A_i^c$ for each $i$,
    and taking the complement of both sides, giving us
    \[
      \bigcap_{i=1}^n B_i^c = \left(\bigcup_{i=1}^nB_i\right)^c.
    \]
    Since taking complements on both sides of an equation preserves equality,
    we will only attempt to prove the first formulation by 
    mathematical induction.\\
    Base case: when $n=2$, we have
    \[
      \left(\bigcap_{i=1}^2 A_i\right)^c = \bigcup_{i=1}^2A_i^c.
    \]
    Proof of base case: An element $x$ is in the left hand side if and only if
    $x$ is not in the intersection of $A_1$ and $A_2$. This means
    $x$ is not in $A_1$ or $x$ is not in $A_2$. This is equivalent to
    saying $x$ is in the complement of $A_1$ or $x$ is in the complement of
    $A_2$, which is equivalent to saying $x$ is in the union of the
    complements of $A_1$ and $A_2$.\\\\
    Inductive hypothesis: Assume that for some $k \ge 2$,
    \[
      \left(\bigcap_{i=1}^k A_i\right)^c = \bigcup_{i=1}^kA_i^c.
    \]
    Inductive step: We want to show that
    \[
      \left(\bigcap_{i=1}^{k+1} A_i\right)^c = \bigcup_{i=1}^{k+1}A_i^c.
    \]
    Proof of inductive step: First we can rewrite the left hand side as
    \[
      \left(\bigcap_{i=1}^{k+1} A_i\right)^c = \left(A_{k+1} \cap
      \bigcap_{i=1}^k A_i\right)^c.
    \]
    By the case $n=2$ of DeMorgan's Laws, we have
    \[
      \left(A_{k+1} \cap \bigcap_{i=1}^k A_i\right)^c = A_{k+1}^c \cup
      \left(\bigcap_{i=1}^k A_i\right)^c.
    \]
    By the inductive hypothesis, we have
    \[
      A_{k+1}^c \cup \left(\bigcap_{i=1}^k A_i\right)^c = A_{k+1}^c \cup
      \bigcup_{i=1}^kA_i^c.
    \]
    Finally, we have
    \[
      A_{k+1}^c \cup \bigcup_{i=1}^kA_i^c = \bigcup_{i=1}^{k+1}A_i^c.
    \]
  \end{itemize}
\end{problem}

\begin{problem}{5} The lifetime $X$ of a cell phone battery, inspected
  under stress, satisfies\\ 
  $\Prob(X>t) = e^{-t/10}$ for all $t>0$.
  \begin{enumerate}
    \item Show that, if $0 \le a < b$ then 
    $\Prob(a < X \le b) = \frac{1}{10}\int_a^b e^{-t/10}dt$.
    \item Is there a similar internal representation for 
    $\Prob(a < X \le b) = \int_a^b g(t)dt$ valid even if $a<0<b$
    Hint: use an indicator function -- 
    it should not depend on either $a$ or $b$?
    \item Let $a \to b$ to find $\Prob(X=b)$.
  \end{enumerate}
  
\end{problem}
% --------------------------------------------------------------
%     You don't have to mess with anything below this line.
% --------------------------------------------------------------
\end{document}